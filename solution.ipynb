{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtro de Spam \n",
    "\n",
    "Este projeto, proposto na disciplina de **Aprendizado de Máquina**, tem como objetivo classificar e-mails como spam ou legítimos através do algoritmo _Naive Bayes_.\n",
    "\n",
    "Estaremos utilizando o [dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) da _UCI Machine Learning Repository_.\n",
    "\n",
    "O trabalho está dividido da seguinte forma:\n",
    "1. [Implementar os tópicos em \"ToDo\";](#implementar-todos)\n",
    "2. [Explicar o que significa \"Bag of Words\";](#bag-of-words)\n",
    "3. [Explicar a diferença entre especificidade e sensitividade;](#especificidade-x-sensitividade)\n",
    "4. [Implementar o Naive Bayes e comparar com um dos algoritmos vistos no ML tour;](#naive-bayes-x-regressão-logística)\n",
    "5. [Fazer uma lista dos prós e contras do Naive Bayes e do algoritmo escolhido.](#prós-e-contras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar ToDos\n",
    "\n",
    "> **Instrução:** Responder/implementar corretamente todos os tópicos em \"ToDo\"\n",
    "\n",
    "Este tópico foi inteiramente resolvido dentro de [Bayesian_Inference.ipynb](Bayesian_Inference.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "\n",
    "> **Instrução:** Explicar o que significa o \"Bag of Words\"\n",
    "\n",
    "_Bag of Words_ (BoW) é uma técnica utilizada para representar dados de texto como um vetor numérico. Ela essencialmente conta a frequência de palavras ignorando a ordem em que elas ocorrem.\n",
    "\n",
    "De forma exemplificada, considere as seguintes frases:\n",
    "- **Frase 0:** O tempo perguntou ao tempo quanto tempo o tempo tem\n",
    "- **Frase 1:** Uma breve história do tempo\n",
    "\n",
    "Podemos visualizá-las em forma de matriz: cada linha `i` representa uma frase, enquanto a coluna `j` representa uma palavra. A entrada `ij` da matriz guarda a frequência em que a palavra `j` aparece na frase `i`. \n",
    "\n",
    "Ignorando a diferença entre maiúsculas e minúsculas, teríamos:\n",
    "\n",
    "|   | o | tempo | perguntou | ao | quanto | tem | uma | breve | história | do |\n",
    "|:-:|:-:|:-----:|:---------:|:--:|:------:|:---:|:---:|:-----:|:--------:|:--:|\n",
    "| **0** | 2 | 4 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 0 |\n",
    "| **1** | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificidade x Sensitividade\n",
    "\n",
    "> **Instrução:** Explicar a diferença entre especificidade e sensitividade. Dê dois exemplos práticos, uma em que a especificidade parece ser mais adequada do que a sensitividade e vice-versa\n",
    "\n",
    "A **sensitividade** de um teste, também chamada de taxa de verdadeiro positivo (TPR) ou  _recall_, é a taxa de positivos que foram corretamente identificados como positivos\n",
    "\n",
    "A sensibilidade pode ser calculada da seguinte forma:\n",
    "```\n",
    "sensibilidade = #[verdadeiros positivos] / (#[verdadeiros positivos] + #[falsos negativos])\n",
    "```\n",
    "\n",
    "Já a **especificidade** de um teste, também chamada de taxa de verdadeiro negativo (TNR), é a taxa de negativos que foram corretamente identificados como negativos, i.e, \n",
    "```\n",
    "especificidade = #[verdadeiros negativos] / (#[verdadeiros negativos] + #[falsos positivos])\n",
    "```\n",
    "\n",
    "A escolha entre algoritmos que priorizam sensibilidade ou especificidade depende diretamente da natureza do problema.\n",
    "\n",
    "Por exemplo, em um teste para detecção de câncer, é importante priorizar a sensitividade para garantir que a maior parte dos casos positivos seja identificada. Perder um positivo (paciente com câncer) por falta de tratamento seria muito grave.\n",
    "\n",
    "Em contrapartida, um filtro de spam deve priorizar a especificidade. Receber um spam é menos pior do que perder uma mensagem importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes x Regressão logística\n",
    "\n",
    "> **Instrução:** Implementar o Naive Bayes conforme indica o roteiro e comparar com um (1) dos algoritmos vistos no ML tour, justificando a escolha do melhor modelo. É para comparar o Naive Bayes com um e apenas um algoritmo\n",
    "\n",
    "Como visto em [Bayesian_Inference.ipynb](Bayesian_Inference.ipynb), os resultados que tivemos com o _Naive Bayes_ foram os seguintes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score\n",
    "nb_accuracy = 0.9885139985642498\n",
    "\n",
    "# Precision score  \n",
    "nb_precision = 0.9720670391061452\n",
    "\n",
    "# Recall score\n",
    "nb_recall = 0.9405405405405406\n",
    "\n",
    "# F1 score\n",
    "nb_f1 = 0.9560439560439562"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faremos o mesmo com a Regressão Logística para fins de comparação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('collection/SMSSpamCollection', \n",
    "                    sep='\\t',\n",
    "                    names=['label', 'message'])\n",
    "\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'],\n",
    "                                                    df['label'],\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(training_data, y_train)\n",
    "predictions = logistic_regression.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9877961234745154\n",
      "Precision score:  0.9941176470588236\n",
      "Recall score:  0.9135135135135135\n",
      "F1 score:  0.9521126760563381\n"
     ]
    }
   ],
   "source": [
    "# solutions\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Accuracy score\n",
    "lr_accuracy = accuracy_score(y_test, predictions)\n",
    "print('Accuracy score: ', format(lr_accuracy))\n",
    "\n",
    "# Precision score  \n",
    "lr_precision = precision_score(y_test, predictions)\n",
    "print('Precision score: ', format(lr_precision))\n",
    "\n",
    "# Recall score\n",
    "lr_recall = recall_score(y_test, predictions)\n",
    "print('Recall score: ', format(lr_recall))\n",
    "\n",
    "# F1 score\n",
    "lr_f1 = f1_score(y_test, predictions)\n",
    "print('F1 score: ', format(lr_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação dos resultados\n",
    "\n",
    "**1. Accuracy**\n",
    "\n",
    "- **Naive Bayes:** 0.9885139985642498\n",
    "- **Regressão Logística:** 0.9877961234745154\n",
    "\n",
    "Esta métrica mede a proporção de previsões corretas feitas pelo modelo em todo o conjunto de dados. Note que ambos tiveram resultados próximos, porém o Naive Bayes teve uma pequena vantagem. \n",
    "\n",
    "**2. Precision**\n",
    "\n",
    "- **Naive Bayes:** 0.9720670391061452\n",
    "- **Regressão Logística:** 0.9941176470588236\n",
    "\n",
    "_Precision_ mede a proporção de previsões de verdadeiros positivos entre todas as previsões positivas feitas pelo modelo. Uma precisão maior significa menos falsos positivos, ou seja, menos e-mails legítimos serão erroneamente classificados como spam.\n",
    "\n",
    "Nesse caso, a Regressão Logística demonstrou melhor desempenho.\n",
    "\n",
    "**3. Recall**\n",
    "\n",
    "- **Naive Bayes:** 0.9405405405405406\n",
    "- **Regressão Logística:** 0.9135135135135135\n",
    "\n",
    "O _recall_ (sensitividade) mede a proporção de instâncias positivas que foram identificadas corretamente, isto é, um _recall_ mais alto significa que o modelo é melhor em identificar todos os e-mails de spam.\n",
    "\n",
    "Naive Bayes tem um recall maior em comparação com a Regressão Logística. \n",
    "\n",
    "**4. F1**\n",
    "\n",
    "- **Naive Bayes:** 0.9560439560439562\n",
    "- **Regressão Logística:** 0.9521126760563381\n",
    "\n",
    "_F1_ equilibra em uma única métrica o _recall_ e a precisão. Ambos algorítmos atingem valores semelhantes, porém Naive Bayes está levemente acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual escolher?\n",
    "\n",
    "Ambos os modelos possuem bons desempenhos em todas as métricas (> 90%). Naive Bayes é um pouco melhor no geral devido ao seu _recall_ mais alto e _F1_, tornando-se uma boa opção caso o objetivo seja determinar com mais precisão os e-mails que são spam. Entretanto, se evitar que e-mails legítimos sejam erroneamente classificados como spam for mais importante, a Regressão Logística se sai melhor, visto que possui _precision_ maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prós e contras\n",
    "\n",
    "> **Instrução:** Você deverá fazer uma lista dos prós e contras do Naive Bayes e do algoritmo escolhido. Você deve explicar o resultado obtido com base nas características dos dois algoritmos avaliado. Você teria algum insight relevante para me apresentar?\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- **Baixo _overfitting_:** esse modelo causa pouco _overfitting_ em comparação com outros algoritmos, por conta disso, as 4 métricas possuem bons valores no geral;\n",
    "\n",
    "- **Bom com pequenos conjuntos de dados:** Naive Bayes é um algoritmo simples e eficiente, se dando muito bem com conjuntos menores de dados. Este é o nosso caso, já que estamos trabalhando com uma lista de apenas 5574 mensagens.\n",
    "\n",
    "\n",
    "**Cons**\n",
    "\n",
    "- **Assume independência:** Naive Bayes assume que todas as palavras são independentes umas das outras, o que normalmente não é verdade. Isso pode levar a um número maior de falsos positivos, reduzindo a precisão;\n",
    "\n",
    "- **Zero-frequency problem:** isso acontece quando uma variável, no nosso caso uma palavra, está ausente nos dados de treinamento. Por exemplo, se \"maçã\" não estiver nos dados de treinamento para \"spam\", sua probabilidade será zero, tornando também a probabilidade geral zero.\n",
    "\n",
    "### Regressão Logística\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- **Não assume independência:** ao contrário do Naive Bayes, a Regressão não assume independência entre as palavras, influenciando na maior _precision_ do modelo;\n",
    "\n",
    "- **Simples de interpretar:** isso acontece pois a probabilidade é calculada como uma combinação linear das variáveis.\n",
    "\n",
    "**Cons**\n",
    "\n",
    "- **Maior _overfitting_:** a Regressão Logística é mais propensa a _overfitting_ em relação ao Naive Bayes. Essa pode ser uma das causas da diferença entre Accuracy e Recall ser maior quando comparado ao Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "**Naive Bayes:** Esse modelo obteve melhor _recall_, o que significa que está detectando melhor as mensagens de spam. Pode ser uma boa escolha se detectá-los for mais importante, mesmo que alguns falsos positivos passem despercebídos.\n",
    "\n",
    "**Regressão logística:** Já esse modelo possui maior precisão, então ele é melhor em evitar falsos positivos (rotulando não spam como spam). É mais adequado se minimizar os falsos positivos for uma prioridade, mesmo que isso signifique que algumas mensagens de spam passem como legítimas.\n",
    "\n",
    "Particularmente, acredito que minimizar que e-mails legítimos sejam classificados como spam é mais importante do que o contrário; focar em maior _precision_ se torna melhor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
