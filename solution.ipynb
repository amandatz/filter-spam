{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtro de Spam \n",
    "\n",
    "Este projeto, proposto na disciplina de **Aprendizado de Máquina**, tem como objetivo classificar e-mails como spam ou legítimos através do algoritmo _Naive Bayes_.\n",
    "\n",
    "Estaremos utilizando o [dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) da _UCI Machine Learning Repository_.\n",
    "\n",
    "O trabalho está dividido da seguinte forma:\n",
    "1. Implementar os tópicos em \"ToDo\";\n",
    "2. Explicar o que significa \"Bag of Words\";\n",
    "3. Explicar a diferença entre especificidade e sensitividade;\n",
    "4. Implementar o Naive Bayes e comparar com um dos algoritmos vistos no ML tour;\n",
    "5. Fazer uma lista dos prós e contras do Naive Bayes e do algoritmo escolhido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar ToDos\n",
    "\n",
    "> **Instrução:** Responder/implementar corretamente todos os tópicos em \"ToDo\"\n",
    "\n",
    "Este tópico foi inteiramente resolvido dentro de [Bayesian_Inference.ipynb](Bayesian_Inference.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "\n",
    "> **Instrução:** Explicar o que significa o \"Bag of Words\"\n",
    "\n",
    "_Bag of Words_ (BoW) é uma técnica utilizada para representar dados de texto como um vetor numérico. Ela essencialmente conta a frequência de palavras ignorando a ordem em que elas ocorrem.\n",
    "\n",
    "De forma exemplificada, considere as seguintes frases:\n",
    "- **Frase 0:** O tempo perguntou ao tempo quanto tempo o tempo tem\n",
    "- **Frase 1:** Uma breve história do tempo\n",
    "\n",
    "Podemos visualizá-las em forma de matriz: cada linha `i` representa uma frase, enquanto a coluna `j` representa uma palavra. A entrada `ij` da matriz guarda a frequência em que a palavra `j` aparece na frase `i`. \n",
    "\n",
    "Ignorando a diferença entre maiúsculas e minúsculas, teríamos:\n",
    "\n",
    "|   | o | tempo | perguntou | ao | quanto | tem | uma | breve | história | do |\n",
    "|:-:|:-:|:-----:|:---------:|:--:|:------:|:---:|:---:|:-----:|:--------:|:--:|\n",
    "| **0** | 2 | 4 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 0 |\n",
    "| **1** | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificidade x Sensitividade\n",
    "\n",
    "> **Instrução:** Explicar a diferença entre especificidade e sensitividade. Dê dois exemplos práticos, uma em que a especificidade parece ser mais adequada do que a sensitividade e vice-versa\n",
    "\n",
    "A **sensitividade** de um teste, também chamada de taxa de verdadeiro positivo (TPR) ou  _recall_, é a taxa de positivos que foram corretamente identificados como positivos\n",
    "\n",
    "A sensibilidade pode ser calculada da seguinte forma:\n",
    "\n",
    "```\n",
    "sensibilidade = #[verdadeiros positivos] / (#[verdadeiros positivos] + #[falsos negativos])\n",
    "```\n",
    "\n",
    "Já a **especificidade** de um teste, também chamada de taxa de verdadeiro negativo (TNR), é a taxa de negativos que foram corretamente identificados como negativos, i.e, \n",
    "\n",
    "```\n",
    "especificidade = #[verdadeiros negativos] / (#[verdadeiros negativos] + #[falsos positivos])\n",
    "```\n",
    "\n",
    "O ideal é que tanto a sensitividade quanto a especificidade tenham os maiores valores possível, mas nem sempre isso é possível. A escolha entre algoritmos que priorizam sensibilidade ou especificidade depende diretamente da natureza do problema.\n",
    "\n",
    "Por exemplo, em um teste para detecção de câncer, é importante priorizar a sensitividade para garantir que a maior parte dos casos positivos seja identificada. Perder um positivo (paciente com câncer) por falta de tratamento seria muito grave.\n",
    "\n",
    "Em contrapartida, um filtro de spam deve priorizar a especificidade. Receber um spam é menos pior do que perder uma mensagem importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes x Regressão logística\n",
    "\n",
    "> **Instrução:** Implementar o Naive Bayes conforme indica o roteiro e comparar com um (1) dos algoritmos vistos no ML tour, justificando a escolha do melhor modelo. É para comparar o Naive Bayes com um e apenas um algoritmo\n",
    "\n",
    "Como visto em [Bayesian_Inference.ipynb](Bayesian_Inference.ipynb), os resultados que tivemos com o _Naive Bayes_ foram os seguintes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_accuracy = 0.9885139985642498\n",
    "\n",
    "nb_precision = 0.9720670391061452\n",
    "\n",
    "nb_recall = 0.9405405405405406\n",
    "\n",
    "nb_f1 = 0.9560439560439562\n",
    "\n",
    "nb_specificity = 0.9958609271523179"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faremos o mesmo com a Regressão Logística para fins de comparação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_table('collection/SMSSpamCollection', \n",
    "                    sep='\\t',\n",
    "                    names=['label', 'message'])\n",
    "\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'],\n",
    "                                                    df['label'],\n",
    "                                                    random_state=1)\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "testing_data = count_vector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(training_data, y_train)\n",
    "predictions = logistic_regression.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcularemos as métricas da Regressão Logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9885139985642498\n",
      "Precision score:  0.9567567567567568\n",
      "Recall score:  0.9567567567567568\n",
      "F1 score:  0.9567567567567568\n",
      "Specificity:  0.9933774834437086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "\n",
    "print('Precision score: ', format(precision_score(y_test, predictions)))\n",
    "\n",
    "print('Recall score: ', format(recall_score(y_test, predictions)))\n",
    "\n",
    "print('F1 score: ', format(f1_score(y_test, predictions)))\n",
    "\n",
    "lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, predictions).ravel()\n",
    "lr_specificity = lr_tn / (lr_tn+lr_fp)\n",
    "print('Specificity: ', format(lr_specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação dos resultados\n",
    "\n",
    "**1. Accuracy**\n",
    "\n",
    "- **Naive Bayes:** 0.9885139985642498\n",
    "- **Regressão Logística:** 0.9877961234745154\n",
    "\n",
    "Esta métrica mede a proporção de previsões corretas feitas pelo modelo em todo o conjunto de dados. Note que ambos tiveram resultados próximos, porém o Naive Bayes teve uma pequena vantagem. \n",
    "\n",
    "**2. Precision**\n",
    "\n",
    "- **Naive Bayes:** 0.9720670391061452\n",
    "- **Regressão Logística:** 0.9941176470588236\n",
    "\n",
    "_Precision_ mede a proporção de previsões de verdadeiros positivos entre todas as previsões positivas. Uma precisão maior significa menos falsos positivos, ou seja, menos e-mails legítimos serão erroneamente classificados como spam.\n",
    "\n",
    "Nesse caso, a Regressão Logística demonstrou melhor desempenho.\n",
    "\n",
    "**3. Recall**\n",
    "\n",
    "- **Naive Bayes:** 0.9405405405405406\n",
    "- **Regressão Logística:** 0.9135135135135135\n",
    "\n",
    "O _recall_ (sensitividade) mede a proporção de positivos que foram identificadas corretamente, isto é, um _recall_ mais alto significa que o modelo é melhor em identificar todos os e-mails de spam.\n",
    "\n",
    "Naive Bayes tem um recall maior em comparação com a Regressão Logística. \n",
    "\n",
    "**4. F1**\n",
    "\n",
    "- **Naive Bayes:** 0.9560439560439562\n",
    "- **Regressão Logística:** 0.9521126760563381\n",
    "\n",
    "_F1_ equilibra em uma única métrica o _recall_ e a precisão. Ambos algorítmos atingem valores semelhantes, porém Naive Bayes está levemente acima.\n",
    "\n",
    "**5. Specificity**\n",
    "\n",
    "- **Naive Bayes:** 0.9958609271523179\n",
    "- **Regressão Logística:** 0.99917218543046361\n",
    "\n",
    "Como já dito anteriormente, a especificidade mede a taxa de negativos corretamente denominados como tal. Note que a Regressão Logística levou vantagem, isso significa que ela foi melhor em classificar e-mails legítimos como legítimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual escolher?\n",
    "\n",
    "Ambos os modelos possuem bons desempenhos em todas as métricas (> 90%). Levando em consideração que especificidade e _precision_ são mais importantes nesse contexto, visto que queremos evitar que e-mails legítimos sejam erroneamente classificicados como spam, a Regressão Logística é a melhor escolha. Embora o Naive Bayes leve vantagem em algumas métricas, a diferença não é tão expressiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prós e contras\n",
    "\n",
    "> **Instrução:** Você deverá fazer uma lista dos prós e contras do Naive Bayes e do algoritmo escolhido. Você deve explicar o resultado obtido com base nas características dos dois algoritmos avaliado. Você teria algum insight relevante para me apresentar?\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- **Baixo _overfitting_:** esse modelo causa pouco _overfitting_ em comparação com outros algoritmos, por conta disso, as 4 métricas possuem bons valores no geral;\n",
    "\n",
    "- **Bom com pequenos conjuntos de dados:** Naive Bayes é um algoritmo simples e eficiente, se dando muito bem com conjuntos menores de dados. Este é o nosso caso, já que estamos trabalhando com uma lista de apenas 5574 mensagens.\n",
    "\n",
    "\n",
    "**Cons**\n",
    "\n",
    "- **Assume independência:** Naive Bayes assume que todas as palavras são independentes umas das outras, o que normalmente não é verdade. Isso pode levar a um número maior de falsos positivos, reduzindo a precisão;\n",
    "\n",
    "- **Zero-frequency problem:** isso acontece quando uma variável, no nosso caso uma palavra, está ausente nos dados de treinamento. Por exemplo, se \"maçã\" não estiver nos dados de treinamento para \"spam\", sua probabilidade será zero, tornando também a probabilidade geral zero.\n",
    "\n",
    "### Regressão Logística\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- **Bom para classificação binária:** é exatamente esse o propósito do filtro de spam: classificar as mensagens entre spam ou ham;\n",
    "\n",
    "- **Simples de interpretar:** isso acontece pois a probabilidade é calculada como uma combinação linear das variáveis.\n",
    "\n",
    "**Cons**\n",
    "\n",
    "- **Maior _overfitting_:** a Regressão Logística é mais propensa a _overfitting_ em relação ao Naive Bayes. Essa pode ser uma das causas da diferença entre Accuracy e Recall ser maior quando comparado ao Naive Bayes;\n",
    "\n",
    "- **Assume Separabilidade Linear:** se as mensagens de spam e ham não forem claramente separáveis com uma linha reta, a regressão logística pode não capturar tais nuances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "**Naive Bayes:** Esse modelo obteve melhor _recall_, o que significa que está detectando melhor as mensagens de spam. Pode ser uma boa escolha se detectá-los for mais importante, mesmo que alguns falsos positivos passem despercebídos.\n",
    "\n",
    "**Regressão logística:** Já esse modelo possui maior precisão e especificidade, então ele é melhor em evitar falsos positivos (rotulando não spam como spam). É mais adequado se minimizar os falsos positivos for uma prioridade, mesmo que isso signifique que algumas mensagens de spam passem como legítimas.\n",
    "\n",
    "Particularmente, acredito que minimizar que e-mails legítimos sejam classificados como spam é mais importante do que o contrário; focar em maior especificidade se torna melhor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
